# Production Quick Start Guide

## 🚀 **Get Started in 5 Minutes**

This guide will help you deploy the InterviewIQ Vector Database Integration to production quickly and safely.

## 📋 **Prerequisites**

- Docker and Docker Compose installed
- OpenAI API key
- 4GB+ RAM available
- 10GB+ disk space

## ⚡ **Quick Setup**

### **1. Run the Setup Script**

```bash
# Make the script executable and run it
chmod +x scripts/setup-production.sh
./scripts/setup-production.sh
```

This script will:
- ✅ Check prerequisites
- ✅ Create production configuration files
- ✅ Generate secure passwords and keys
- ✅ Set up Docker Compose configuration
- ✅ Create deployment and monitoring scripts

### **2. Configure Your OpenAI API Key**

```bash
# Edit the production environment file
nano .env.prod

# Find this line and replace with your actual API key:
OPENAI_API_KEY=your_openai_api_key_here
```

### **3. Deploy to Production**

```bash
# Deploy the application
./scripts/deploy-production.sh
```

This will:
- 🏗️ Build the application image
- 🚀 Start all services (PostgreSQL, Qdrant, Redis, App, Nginx)
- 🗄️ Run database migrations
- 🔍 Initialize vector collections
- ✅ Run health checks

### **4. Verify Deployment**

```bash
# Check service status
./scripts/monitor-production.sh

# Or manually check health
curl http://localhost/health
curl http://localhost/api/v1/vector/health
```

## 🌐 **Access Your Application**

| Service | URL | Description |
|---------|-----|-------------|
| **Application** | http://localhost | Main application |
| **API Documentation** | http://localhost/docs | Interactive API docs |
| **Health Check** | http://localhost/health | System health status |
| **Vector Health** | http://localhost/api/v1/vector/health | Vector database status |

## 🔧 **Production Usage Examples**

### **1. Generate Interview Questions**

```bash
# Generate questions for a Python developer role
curl -X POST "http://localhost/api/v1/vector/suggestions/questions" \
  -H "Content-Type: application/json" \
  -d '{
    "job_description": "We are looking for a Senior Python Developer with experience in FastAPI, PostgreSQL, and Docker. The ideal candidate should have strong problem-solving skills and experience with microservices architecture.",
    "role": "python_developer",
    "difficulty": "medium",
    "count": 5
  }'
```

### **2. Search Similar Questions**

```bash
# Search for questions about async programming
curl -X POST "http://localhost/api/v1/vector/search/questions" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Python async programming concepts",
    "filters": {
      "difficulty": "medium",
      "category": "technical"
    },
    "limit": 10
  }'
```

### **3. Get Personalized Recommendations**

```bash
# Get recommendations for a user
curl -X POST "http://localhost/api/v1/vector/recommendations" \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "user_123",
    "content_type": "questions",
    "user_profile": {
      "skill_level": "intermediate",
      "learning_style": "practical",
      "preferred_categories": ["technical", "behavioral"]
    },
    "limit": 10
  }'
```

### **4. Generate Embeddings**

```bash
# Generate embedding for text
curl -X POST "http://localhost/api/v1/vector/embeddings/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Python async programming concepts",
    "model": "text-embedding-3-small",
    "use_cache": true
  }'
```

## 📊 **Monitoring and Maintenance**

### **Daily Monitoring**

```bash
# Check system health
./scripts/monitor-production.sh

# View application logs
docker-compose -f docker-compose.prod.yml logs -f app

# Check resource usage
docker stats
```

### **Weekly Maintenance**

```bash
# Update application
git pull
docker-compose -f docker-compose.prod.yml build
docker-compose -f docker-compose.prod.yml up -d

# Backup database
docker-compose -f docker-compose.prod.yml exec postgres pg_dump -U interviewiq_prod interviewiq_prod > backup.sql
```

### **Health Check Endpoints**

```bash
# Overall system health
curl http://localhost/health | jq

# Vector database health
curl http://localhost/api/v1/vector/health | jq

# Collection statistics
curl http://localhost/api/v1/vector/collections | jq

# Available models
curl http://localhost/api/v1/vector/models | jq
```

## 🔒 **Security Best Practices**

### **1. Environment Security**

```bash
# Secure your environment file
chmod 600 .env.prod

# Use strong passwords (already generated by setup script)
# Rotate secrets regularly
```

### **2. Network Security**

```bash
# Use HTTPS in production (configure SSL certificates)
# Set up firewall rules
# Use VPN for database access
```

### **3. API Security**

```bash
# Implement rate limiting (already configured)
# Use API keys for external access
# Monitor for suspicious activity
```

## 🚨 **Troubleshooting**

### **Common Issues**

1. **Services won't start**
   ```bash
   # Check logs
   docker-compose -f docker-compose.prod.yml logs
   
   # Check disk space
   df -h
   
   # Check memory
   free -h
   ```

2. **Vector search not working**
   ```bash
   # Check Qdrant health
   curl http://localhost:6333/health
   
   # Reinitialize collections
   curl -X POST "http://localhost/api/v1/vector/collections/initialize"
   ```

3. **High memory usage**
   ```bash
   # Check resource usage
   docker stats
   
   # Restart services
   docker-compose -f docker-compose.prod.yml restart
   ```

### **Emergency Procedures**

```bash
# Emergency restart
docker-compose -f docker-compose.prod.yml restart

# Emergency stop
docker-compose -f docker-compose.prod.yml down

# Emergency logs
docker-compose -f docker-compose.prod.yml logs --tail=100
```

## 📈 **Scaling for Production**

### **Horizontal Scaling**

```bash
# Scale application instances
docker-compose -f docker-compose.prod.yml up -d --scale app=3

# Use load balancer (nginx already configured)
```

### **Database Scaling**

```bash
# Add read replicas
# Use connection pooling
# Implement caching strategies
```

### **Vector Database Scaling**

```bash
# Use Qdrant cluster mode
# Implement vector caching
# Optimize collection parameters
```

## 🔄 **Backup and Recovery**

### **Automated Backup**

```bash
# Create backup script
cat > scripts/backup.sh << 'EOF'
#!/bin/bash
BACKUP_DIR="/backups/$(date +%Y%m%d_%H%M%S)"
mkdir -p $BACKUP_DIR

# Database backup
docker-compose -f docker-compose.prod.yml exec postgres pg_dump -U interviewiq_prod interviewiq_prod > $BACKUP_DIR/db.sql

# Qdrant backup
curl -X POST "http://localhost:6333/collections/job_descriptions/snapshots"
curl -X POST "http://localhost:6333/collections/questions/snapshots"

echo "Backup completed: $BACKUP_DIR"
EOF

chmod +x scripts/backup.sh
```

### **Recovery**

```bash
# Restore database
docker-compose -f docker-compose.prod.yml exec postgres psql -U interviewiq_prod interviewiq_prod < backup.sql

# Restore Qdrant (manual process)
# Download snapshots from Qdrant dashboard
```

## 📚 **Additional Resources**

- **Full Production Guide**: `docs/PRODUCTION_DEPLOYMENT_GUIDE.md`
- **Vector Database Guide**: `docs/VECTOR_DATABASE_GUIDE.md`
- **API Documentation**: http://localhost/docs (after deployment)
- **Health Monitoring**: http://localhost/health

## 🆘 **Support**

If you encounter issues:

1. Check the troubleshooting section above
2. Review the logs: `docker-compose -f docker-compose.prod.yml logs`
3. Check health endpoints: `curl http://localhost/health`
4. Review the comprehensive documentation

---

**🎉 Congratulations! You now have a production-ready InterviewIQ Vector Database Integration running with intelligent semantic search capabilities!**
